{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logestic Regression Modeling with Cross Validation on Word Frequecy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: load dependencies and read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = pd.read_csv(\"data/reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: _Term Frequency - Inverse Document Frequenc (TF-IDF)_ Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF means \"Term Frequency - Inverse Document Frequency\". It is a powerful technique to detect important words in a collection of documents. \"Term Frequency\" (TF) meansures the frequency of word $w_i$ in document $d_j$, and the \"Inverse Document Frequency\" (IDF) measures how much information the word provides, i.e., the frequency of word $w_i$ in the collection of documents. The TF-IDF value for a word $w_i$ in document $d_j$ is positively associated with word frequencies and negatively associated with document frequencies. The math formula for TF-IDF is:\n",
    "\n",
    "$$TF-IDF(w_i, d_j) = TF(w_i, d_j) \\times IDF(w_i)$$\n",
    "\n",
    "And IDF can be smoothed using the formula:\n",
    "\n",
    "$$IDF_{smooth}(w_i) = log(\\frac{N}{1 + n_i})$$\n",
    "\n",
    "where $N$ is the number of documents considered and $n_i$ is the frequency of $w_i$ in the all documents considered.\n",
    "\n",
    "In this project, TF-IDF is used in logistic regression classification. In the following analysis, we did several steps to fit the best logistic regression model:\n",
    "\n",
    "1. constructed the TF-IDF matrix, \n",
    "2. used $\\chi^2$ independent test to select top $1,000$ keywords from training set,\n",
    "3. computed the TF-IDF values of the $1,000$ keywords,\n",
    "4. splited the whole dataset into training set and validation set using 10-fold cross-valudation,\n",
    "5. used the _TF-IDF values_ as covariates, the _star values_ of review as responses, to build a logistic regression model in the training set,\n",
    "6. tries 3 different tuning parameters respectively,\n",
    "7. applied the models built in training set to validation set and obtained the predicted _star values_ for each tuning parameter,\n",
    "8. computed the Mean Squared Error (MSE) between true _star value_ and predicted _star value_ in validation set, \n",
    "9. and chose the optimal tuning parameters which produces lowest MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construct the TF-IDF matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make raw dataset into the format for TF-idf transformation\n",
    "star = np.array(review.stars)\n",
    "text = list(map(lambda x: x[2:-1].replace(\"\\\\n\",\"\\n\"), review.text))\n",
    "pat = re.compile(r\"[^\\w\\s]\")\n",
    "text_clean = np.array(list(map(lambda x: pat.sub(\" \",x).lower(), text)))\n",
    "\n",
    "# create TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words = \"english\")\n",
    "text_features = vectorizer.fit_transform(text_clean)\n",
    "vocab = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in the text_features dataset is 60222 \n",
      "Number of covariates in the text_features dataset is 50137\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of observations in the text_features dataset is\", text_features.shape[0],\n",
    "      \"\\nNumber of covariates in the text_features dataset is\", text_features.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Compute MSE\n",
    "### Write a function to compute step 2 to 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_CV_mse(df_text, df_star, n_fold, n_words, seed, parameters):\n",
    "    \"\"\"Return the Mean Squared Error (MSE) between predictied reponses and true responses in validation set.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    df_text: TF-IDF format sparse matrix\n",
    "    df_star: array of responses in logistic model\n",
    "    n_fold: number of folds in cross-validation, positive integer\n",
    "    n_words: number of keywords selected, positive integer\n",
    "    seed: random seed for splitting training and validation set\n",
    "    parameters: tuning parameters of logistic regression, positive float vector\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    Array\n",
    "        A numeric Array where each value in dimension 0 is the tuning parameter, \n",
    "        and each value in dimension 1 is MSE computed using the corresponding tuning parameter\n",
    "        \n",
    "    Example\n",
    "    -------\n",
    "    \n",
    "    >>> text_features = vectorizer.fit_transform(text_clean)\n",
    "    ... star = np.array(review.stars)\n",
    "    ... compute_CV_mse(text_features, star, 2, 10, 1, (100.0, 1000.0))\n",
    "    \"\"\"\n",
    "    # parameters must be positive\n",
    "    test = False\n",
    "    if isinstance(n_fold, int):\n",
    "        test = True\n",
    "    else:\n",
    "        raise TypeError(\"n_fold is not an integer\")\n",
    "    if n_fold > 0:\n",
    "        test = True\n",
    "    else:\n",
    "        raise ValueError(\"n_fold should be positive\")\n",
    "    if isinstance(n_words, int):\n",
    "        test = True\n",
    "    else:\n",
    "        raise TypeError(\"n_words is not an integer\")\n",
    "    if n_words > 0:\n",
    "        test = True\n",
    "    else:\n",
    "        raise ValueError(\"n_words should be positive\")  \n",
    "    for i in parameters:\n",
    "        if i > 0:\n",
    "            test = True\n",
    "        else:\n",
    "            raise ValueError(\"parameters should be positive\")\n",
    "    # create K-folds\n",
    "    kf = KFold(n_fold, shuffle = True, random_state = seed)\n",
    "    # create empty dataframe\n",
    "    mse = np.zeros([n_fold + 1, len(parameters)])\n",
    "    k = 0\n",
    "    for train_idx,val_idx in kf.split(df_text):\n",
    "        # create training and validation sets\n",
    "        text_features_train = df_text[train_idx]\n",
    "        text_features_val = df_text[val_idx]\n",
    "        star_train = df_star[train_idx]\n",
    "        star_val = df_star[val_idx]\n",
    "        # using $chi^2$ independent test to select top  1,0001,000  keywords from training set\n",
    "        fselect = SelectKBest(chi2, k = n_words)\n",
    "        # transform training set to format that fits fselect functuon\n",
    "        text_features_train = fselect.fit_transform(text_features_train, star_train)\n",
    "        text_features_val = text_features_val[:, fselect.get_support()]\n",
    "        # compute MSE for each parameter\n",
    "        t = 0\n",
    "        for para in parameters:\n",
    "            # logistic regression with C = parameter,\n",
    "            # where C is positive float, indicates \"Inverse of regularization strength\", \n",
    "            # and smaller values specify stronger regularization.\n",
    "            mod_temp = LogisticRegression(C = para)\n",
    "            # fit regression on training set\n",
    "            mod_temp.fit(X = text_features_train, y = star_train)\n",
    "            # predict star values on validation set\n",
    "            pred = mod_temp.predict(X = text_features_val)\n",
    "            # compute MSE as a dataframe, each value is one mse in one validation set\n",
    "            mse[k,t] = sum((pred - star_val)**2)/len(pred)\n",
    "            t+= 1\n",
    "        k+= 1\n",
    "        # compute overall MSE\n",
    "        mse_out = np.mean(mse[1:n_fold,], axis = 0)       \n",
    "    return(np.vstack((parameters, mse_out)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**compute MSE with 10 fold cross-validation, of first 1,000 keywords, with randome splitting seed = 1, and tuning parameters = (100, 1000, 10000, 100000).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output\n",
    "para, mse = compute_CV_mse(df_text = text_features, df_star = star, n_fold = 10, \n",
    "               n_words = 1000, seed = 1, parameters = 10.0**np.arange(2,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tuning parameters used are: [    100.    1000.   10000.  100000.] \n",
      "The MSE computed are: [ 1.0314  1.0313  1.0307  1.0305]\n"
     ]
    }
   ],
   "source": [
    "print(\"The tuning parameters used are:\", para,\n",
    "     \"\\nThe MSE computed are:\", np.round(mse,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_n_words_positive():\n",
    "    \"\"\"Test that when n_words is negative, raise value error\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    try:\n",
    "        compute_CV_mse(df_text = text_features, df_star = star, n_fold = 2, \n",
    "               n_words = -1, seed = 1, parameters = 10.0**np.arange(0,2))\n",
    "    except ValueError:\n",
    "        assert True\n",
    "    else:\n",
    "        assert False\n",
    "def test_n_words_integer():\n",
    "    \"\"\"Test that when n_words is negative, raise value error\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    try:\n",
    "        compute_CV_mse(df_text = text_features, df_star = star, n_fold = 2, \n",
    "               n_words = \"f\", seed = 1, parameters = 10.0**np.arange(0,2))\n",
    "    except TypeError:\n",
    "        assert True\n",
    "    else:\n",
    "        assert False\n",
    "def test_n_folds_positive():\n",
    "    \"\"\"Test that when n_words is negative, raise value error\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    try:\n",
    "        compute_CV_mse(df_text = text_features, df_star = star, n_fold = -2, \n",
    "               n_words = 1, seed = 1, parameters = 10.0**np.arange(0,2))\n",
    "    except ValueError:\n",
    "        assert True\n",
    "    else:\n",
    "        assert False\n",
    "def test_n_folds_integer():\n",
    "    \"\"\"Test that when n_words is negative, raise value error\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    try:\n",
    "        compute_CV_mse(df_text = text_features, df_star = star, n_fold = \"f\", \n",
    "               n_words = 2, seed = 1, parameters = 10.0**np.arange(0,2))\n",
    "    except TypeError:\n",
    "        assert True\n",
    "    else:\n",
    "        assert False\n",
    "def test_parameters_positive():\n",
    "    \"\"\"Test that when n_words is negative, raise value error\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    try:\n",
    "        compute_CV_mse(df_text = text_features, df_star = star, n_fold = 2, \n",
    "               n_words = 1, seed = 1, parameters = (-1,-3))\n",
    "    except ValueError:\n",
    "        assert True\n",
    "    else:\n",
    "        assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_n_words_positive()\n",
    "test_n_words_integer()\n",
    "test_n_folds_positive()\n",
    "test_n_folds_integer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
